{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sphemister/Documents/Github/more-buda-demos/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/sphemister/Documents/Github/more-buda-demos/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    first_time = False\n",
    "    ds = load_from_disk(str(Path(os.path.abspath('.')) / '..' / 'image'/'cats_vs_dogs_tensor'))\n",
    "except:\n",
    "    first_time = True\n",
    "    ds = load_dataset(\"microsoft/cats_vs_dogs\", split='train')\n",
    "id_to_label_name = ['cat','dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_datatypes = set(str(type(feature)) for feature in ds['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'PIL.Image.Image'>\", \"<class 'PIL.JpegImagePlugin.JpegImageFile'>\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time:\n",
    "    ds = ds.select(range(800))\n",
    "    def filter_by_image_size(image):\n",
    "        min_width = 200\n",
    "        min_height = 200\n",
    "        max_width = 512\n",
    "        max_height = 512\n",
    "        width, height = image.size\n",
    "        return min_width <= width <= max_width and min_height <= height <= max_height\n",
    "\n",
    "    torch_preprocessing = transforms.Compose([\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation((-10,10)),\n",
    "        transforms.Resize((256,256)),\n",
    "    ])\n",
    "    def transform_mapper(sample):\n",
    "        # image = sample['image'].convert(\"RGB\")\n",
    "        sample['image'] = torch_preprocessing(sample['image'])\n",
    "        return sample\n",
    "    \n",
    "    filtered_dataset = ds.filter(lambda example: filter_by_image_size(example['image']))\n",
    "    transformed_dataset = filtered_dataset.map(transform_mapper, batched=False)\n",
    "    def cast_to_float32(batch):\n",
    "        batch['image'] = batch['image'].to(torch.float32)\n",
    "        batch['labels'] = batch['labels']\n",
    "        return batch\n",
    "    transformed_dataset = transformed_dataset.map(cast_to_float32)\n",
    "    # save the imageset\n",
    "    transformed_dataset.save_to_disk(str(Path(os.path.abspath('.')) / '..' / 'image'/'cats_vs_dogs_tensor'))\n",
    "else:\n",
    "    transformed_dataset = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesnt save the dataset format to disk in this format\n",
    "transformed_dataset.set_format(type='torch', columns=['image','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = random_split(transformed_dataset, [700, 37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_dogs_dl = DataLoader(ds_train, batch_size=8, shuffle=True, drop_last=True, )\n",
    "cats_dogs_test = DataLoader(ds_test, batch_size=8, shuffle=True, drop_last=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(cats_dogs_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 256, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cat_dog_torch import Cat_Dog_CNN\n",
    "activation_func = nn.ReLU()\n",
    "model = Cat_Dog_CNN(in_channels=3,out_channels=3,num_conv_layers=5,activation_function=activation_func, normalization=True, num_classifications=2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1E-3, weight_decay=1E-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1\n",
      "Training Loss:  0.03956934424309895  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 2\n",
      "Training Loss:  0.03927129622677277  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 3\n",
      "Training Loss:  0.03921694552590107  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 4\n",
      "Training Loss:  0.03919401255318488  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 5\n",
      "Training Loss:  0.03918208742792579  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 6\n",
      "Training Loss:  0.039175304916055725  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 7\n",
      "Training Loss:  0.03917103629002626  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 8\n",
      "Training Loss:  0.03916785279395937  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 9\n",
      "Training Loss:  0.03916582717806443  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Epoch # 10\n",
      "Training Loss:  0.039164359499325695  Accuracy:  1.0\n",
      "Test Accuracy:  1.0\n",
      "Training Took 97.2 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "test_accuracy = []\n",
    "test_loss = []\n",
    "epochs = 10\n",
    "epsilon = 1E-6\n",
    "num_samples = len(cats_dogs_dl.dataset)\n",
    "num_samples -= num_samples%8\n",
    "\n",
    "num_test_samples = len(cats_dogs_test.dataset)\n",
    "num_test_samples -= num_test_samples%8\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    print('Epoch #',epoch)\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for batch_idx, data in enumerate(cats_dogs_dl):\n",
    "        # training\n",
    "        batch_size = data['image'].size(0)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data['image'])\n",
    "        # print('output shape: ', output.shape)\n",
    "        # print('output: ', )\n",
    "        # print('target shape: ', data['labels'].shape)\n",
    "        # print('one hot target: ', nn.functional.one_hot(data['labels']).shape)\n",
    "        loss = loss_func(output, data['labels'])\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # accuracy\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        epoch_accuracy += preds.eq(data['labels']).sum().item()\n",
    "    \n",
    "    epoch_loss /= num_samples\n",
    "    training_loss.append(epoch_loss)\n",
    "    \n",
    "    epoch_accuracy /= num_samples\n",
    "    training_accuracy.append(epoch_accuracy)\n",
    "    print('Training Loss: ', epoch_loss, ' Accuracy: ', epoch_accuracy)\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_test_accuracy = 0\n",
    "    for data in cats_dogs_test:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data['image'])\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            epoch_test_accuracy+= preds.eq(data['labels']).sum().item()\n",
    "    epoch_test_accuracy /= num_test_samples\n",
    "    test_accuracy.append(epoch_test_accuracy)\n",
    "    print('Test Accuracy: ', test_accuracy[-1])\n",
    "    \n",
    "    # epsilon breaking - avoids overfitting\n",
    "    if len(training_loss) > 1 and abs(training_loss[-1] - training_loss[-2])  < epsilon:\n",
    "        break\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f'Training Took {total_time:.1f} seconds')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
